{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Network (no attention)\n",
    "\n",
    "Using code from \n",
    "\n",
    "[1]`https://github.com/ericjang/draw` \n",
    "\n",
    "[2]`https://github.com/ikostrikov/TensorFlow-VAE-GAN-DRAW`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters set\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "#Tensor flow\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn.rnn_cell import LSTMCell\n",
    "#Easy way to get the data :)\n",
    "from tensorflow.examples.tutorials import mnist\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Most of these dimensinos are used from \n",
    "A,B = 28,28 # image width,height\n",
    "img_size = B*A # the canvas size\n",
    "\n",
    "#Using the parameters from [1], as many of these dimensions aren't explicitly mentioned in the paper\n",
    "enc_size = 256 # number of hidden units / output size in LSTM\n",
    "dec_size = 256\n",
    "read_size = 2*img_size\n",
    "write_size = img_size\n",
    "z_size=10 # QSampler output size\n",
    "T=10 # MNIST generation sequence length\n",
    "\n",
    "#These are standard NN net parameters\n",
    "batch_size=100 # training minibatch size\n",
    "train_iters=5000\n",
    "learning_rate=1e-3 # learning rate for optimizer\n",
    "eps=1e-8 # epsilon for numerical stability\n",
    "\n",
    "print \"All parameters set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable roundup\n",
    "\n",
    "## Encoder RNN\n",
    "\n",
    "* x = raw data read from the mnist images\n",
    "* x_hat = error image, x - sigmoid(c_(t-1)) [equation 3 in the paper]\n",
    "\n",
    "* h = encoded data \n",
    "\n",
    "## Decoder RNN\n",
    "* z = samples drawn from the latent distribution [equation 6 in the paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Define all elementary functions needed:\n",
    "\n",
    "# Incredible abstraction in Tensorflow!\n",
    "# Define the LSTMCell\n",
    "# Documentation: https://www.tensorflow.org/versions/r0.7/tutorials/recurrent/index.html\n",
    "lstm_enc = LSTMCell(enc_size, read_size+dec_size) # encoder Op\n",
    "lstm_dec = LSTMCell(dec_size, z_size) # decoder Op\n",
    "\n",
    "DO_SHARE = None #See note below, this is a necessary hack for initialization\n",
    "\n",
    "#And define operations with those LSTMs\n",
    "def encode(state,input):\n",
    "    with tf.variable_scope(\"encoder\",reuse=DO_SHARE):\n",
    "        return lstm_enc(input,state)\n",
    "def decode(state,input):\n",
    "    with tf.variable_scope(\"decoder\",reuse=DO_SHARE):\n",
    "        return lstm_dec(input, state)\n",
    "    \n",
    "#For the Draw network without attention, the DRAW network encoder takes as input \n",
    "#an input image and the error image (h_prev is only used in the attention model)\n",
    "#[equation 17 from the paper]\n",
    "def read(x,x_hat,h_dec_prev):\n",
    "    return tf.concat(1,[x,x_hat])\n",
    "\n",
    "def sampleQ(h_enc):\n",
    "    \"\"\"\n",
    "    Samples Zt ~ normrnd(mu,sigma) via reparameterization trick for normal dist\n",
    "    mu is (batch,z_size)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"mu\",reuse=DO_SHARE):\n",
    "        mu=linear(h_enc,z_size)\n",
    "    with tf.variable_scope(\"sigma\",reuse=DO_SHARE):\n",
    "        logsigma=linear(h_enc,z_size)\n",
    "        sigma=tf.exp(logsigma)\n",
    "    return (mu + sigma*e, mu, logsigma, sigma)\n",
    "\n",
    "# The write function sans-attention is simply the linear Wx + b\n",
    "def linear(x,output_dim):\n",
    "    \"\"\"\n",
    "    affine transformation Wx+b\n",
    "    assumes x.shape = (batch_size, num_features)\n",
    "    \"\"\"\n",
    "    w=tf.get_variable(\"w\", [x.get_shape()[1], output_dim]) \n",
    "    b=tf.get_variable(\"b\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(x,w)+b\n",
    "\n",
    "#[equation 18 from the paper]\n",
    "def write(h_dec):\n",
    "    with tf.variable_scope(\"write\",reuse=DO_SHARE):\n",
    "        return linear(h_dec,img_size)\n",
    "\n",
    "print \"Functions defined.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model defined.\n"
     ]
    }
   ],
   "source": [
    "#Initialize all variables\n",
    "cs=[0]*T # sequence of canvases\n",
    "mus,logsigmas,sigmas=[0]*T,[0]*T,[0]*T # gaussian params generated by SampleQ. We will need these for computing loss.\n",
    "x = tf.placeholder(tf.float32,shape=(batch_size,img_size)) # input (batch_size * img_size)\n",
    "e=tf.random_normal((batch_size,z_size), mean=0, stddev=1) # Qsampler noise\n",
    "\n",
    "# initial states\n",
    "h_dec_prev=tf.zeros((batch_size,dec_size))\n",
    "enc_state=lstm_enc.zero_state(batch_size, tf.float32)\n",
    "dec_state=lstm_dec.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# Build the graph/network (which is done in an unrolled state)\n",
    "for t in range(T):\n",
    "    #Initialize the previos canvas as 0s for the first run\n",
    "    c_prev = tf.zeros((batch_size,img_size)) if t==0 else cs[t-1]\n",
    "    #Create the error image\n",
    "    x_hat=x-tf.sigmoid(c_prev) # error image\n",
    "    \n",
    "    r=read(x,x_hat,h_dec_prev)\n",
    "\n",
    "    #Pass through the lstm_enc. \n",
    "    #Note that the first time encode and decode are called, the reuse flag must be false\n",
    "    #If not, we get the following error: \n",
    "    # \"\"\"Under-sharing: Variable encoder/LSTMCell/W_0 does not exist, disallowed. \n",
    "    # Did you mean to set reuse=None in VarScope?\"\"\"\n",
    "    h_enc,enc_state=encode(enc_state,tf.concat(1,[r,h_dec_prev]))\n",
    "    #Draw from the latest distribution\n",
    "    z,mus[t],logsigmas[t],sigmas[t]=sampleQ(h_enc)\n",
    "    \n",
    "    h_dec,dec_state=decode(dec_state,z)\n",
    "    cs[t]=c_prev+write(h_dec) # store results\n",
    "    h_dec_prev=h_dec\n",
    "    \n",
    "    DO_SHARE=True\n",
    "\n",
    "print \"Model defined.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss and Optimization defined\n"
     ]
    }
   ],
   "source": [
    "# Define cost functions \n",
    "# the final canvas matrix is used to parameterize a bernoulli distrbition D(X|c). Reconstruction loss\n",
    "# is negative log probability. \n",
    "def binary_crossentropy(t,o):\n",
    "    return -(t*tf.log(o+eps) + (1.0-t)*tf.log(1.0-o+eps))\n",
    "\n",
    "# reconstruction term appears to have been collapsed down to a single scalar value (rather than one per item in minibatch)\n",
    "x_recons=tf.nn.sigmoid(cs[-1])\n",
    "\n",
    "# the final canvas matrix is used to parameterize a bernoulli distrbition D(X|c). Reconstruction loss\n",
    "# is negative log probability [Equation 9]\n",
    "# However, Eric Jang's implmentation uses a mean of summed cross-entropy. The results seem reasonable so I am \n",
    "# going to stick with it for now\n",
    "Lx=tf.reduce_sum(binary_crossentropy(x,x_recons),1) # reconstruction term\n",
    "Lx=tf.reduce_mean(Lx) \n",
    "\n",
    "#The latent loss Lz is the sum LK divergence of P(Z) from Q(Z|h)\n",
    "kl_terms=[0]*T\n",
    "for t in range(T):\n",
    "    mu2=tf.square(mus[t])\n",
    "    sigma2=tf.square(sigmas[t])\n",
    "    logsigma=logsigmas[t]\n",
    "    kl_terms[t]=0.5*tf.reduce_sum(mu2+sigma2-2*logsigma,1)-T*.5 # each kl term is (1x minibatch)\n",
    "KL=tf.add_n(kl_terms) # this is 1x minibatch, corresponding to summing kl_terms from 1:T\n",
    "Lz=tf.reduce_mean(KL) # average over minibatches\n",
    "\n",
    "cost=Lx+Lz\n",
    "\n",
    "#As this can be really finnicky, I'm using Eric Jang's implentation directly here\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "grads=optimizer.compute_gradients(cost)\n",
    "for i,(g,v) in enumerate(grads):\n",
    "    if g is not None:\n",
    "        grads[i]=(tf.clip_by_norm(g,5),v) # clip gradients\n",
    "train_op=optimizer.apply_gradients(grads)\n",
    "\n",
    "print \"Loss and Optimization defined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "iter=0 : Lx: 704.066589 Lz: 12.032032\n",
      "iter=100 : Lx: 183.604416 Lz: 10.224628\n",
      "iter=200 : Lx: 142.434021 Lz: 14.685469\n",
      "iter=300 : Lx: 132.711075 Lz: 10.064411\n",
      "iter=400 : Lx: 123.322708 Lz: 9.898042\n",
      "iter=500 : Lx: 119.492767 Lz: 8.898274\n",
      "iter=600 : Lx: 116.605072 Lz: 7.267062\n",
      "iter=700 : Lx: 111.324242 Lz: 7.590939\n",
      "iter=800 : Lx: 101.727829 Lz: 6.738621\n",
      "iter=900 : Lx: 109.313522 Lz: 6.043165\n",
      "iter=1000 : Lx: 101.580818 Lz: 5.975554\n",
      "iter=1100 : Lx: 95.800980 Lz: 5.859427\n",
      "iter=1200 : Lx: 94.580734 Lz: 5.361672\n",
      "iter=1300 : Lx: 94.015938 Lz: 4.736693\n",
      "iter=1400 : Lx: 96.543488 Lz: 4.625828\n",
      "iter=1500 : Lx: 95.452209 Lz: 4.562587\n",
      "iter=1600 : Lx: 94.533417 Lz: 4.475854\n",
      "iter=1700 : Lx: 92.415993 Lz: 4.658720\n",
      "iter=1800 : Lx: 81.389168 Lz: 4.009033\n",
      "iter=1900 : Lx: 91.274391 Lz: 4.366082\n",
      "iter=2000 : Lx: 85.959335 Lz: 3.838874\n",
      "iter=2100 : Lx: 85.176712 Lz: 3.942167\n",
      "iter=2200 : Lx: 85.724884 Lz: 3.526009\n",
      "iter=2300 : Lx: 85.456635 Lz: 3.834774\n",
      "iter=2400 : Lx: 85.134842 Lz: 3.489269\n",
      "iter=2500 : Lx: 83.668640 Lz: 3.327712\n",
      "iter=2600 : Lx: 74.021385 Lz: 3.142755\n",
      "iter=2700 : Lx: 83.380348 Lz: 3.245509\n",
      "iter=2800 : Lx: 80.962456 Lz: 3.161822\n",
      "iter=2900 : Lx: 80.160912 Lz: 3.327130\n",
      "iter=3000 : Lx: 81.573318 Lz: 3.205673\n",
      "iter=3100 : Lx: 78.019798 Lz: 2.956455\n",
      "iter=3200 : Lx: 76.110390 Lz: 2.955685\n",
      "iter=3300 : Lx: 76.588150 Lz: 2.915997\n",
      "iter=3400 : Lx: 77.069046 Lz: 2.913036\n",
      "iter=3500 : Lx: 71.159103 Lz: 2.662891\n",
      "iter=3600 : Lx: 76.390961 Lz: 2.763884\n",
      "iter=3700 : Lx: 71.777336 Lz: 2.529690\n",
      "iter=3800 : Lx: 72.715309 Lz: 2.835146\n",
      "iter=3900 : Lx: 71.799164 Lz: 2.713371\n",
      "iter=4000 : Lx: 74.038231 Lz: 2.504555\n",
      "iter=4100 : Lx: 70.498108 Lz: 2.574197\n",
      "iter=4200 : Lx: 75.218552 Lz: 2.533033\n",
      "iter=4300 : Lx: 73.515221 Lz: 2.433577\n",
      "iter=4400 : Lx: 71.030525 Lz: 2.469859\n",
      "iter=4500 : Lx: 69.721092 Lz: 2.396254\n",
      "iter=4600 : Lx: 70.891296 Lz: 2.405721\n",
      "iter=4700 : Lx: 72.088692 Lz: 2.465278\n",
      "iter=4800 : Lx: 68.526131 Lz: 2.226485\n",
      "iter=4900 : Lx: 68.200058 Lz: 2.282506\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"mnist\"\n",
    "if not os.path.exists(data_directory):\n",
    "    os.makedirs(data_directory)\n",
    "train_data = mnist.input_data.read_data_sets(data_directory, one_hot=True).train # binarized (0-1) mnist data\n",
    "fetches=[]\n",
    "fetches.extend([Lx,Lz,train_op])\n",
    "Lxs=[0]*train_iters\n",
    "Lzs=[0]*train_iters\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "saver = tf.train.Saver() # saves variables learned during training\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "for i in range(train_iters):\n",
    "    xtrain,_=train_data.next_batch(batch_size) # xtrain is (batch_size x img_size)\n",
    "    feed_dict={x:xtrain}\n",
    "    results=sess.run(fetches,feed_dict)\n",
    "    Lxs[i],Lzs[i],_=results\n",
    "    if i%100==0:\n",
    "        print(\"iter=%d : Lx: %f Lz: %f\" % (i,Lxs[i],Lzs[i]))\n",
    "\n",
    "print \"Training completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualizer\n",
    "\n",
    "#Taking visualization code from Eric Jang's plot_data.py\n",
    "def xrecons_grid(X,B,A):\n",
    "    \"\"\"\n",
    "    plots canvas for single time step\n",
    "    X is x_recons, (batch_size x img_size)\n",
    "    assumes features = BxA images\n",
    "    batch is assumed to be a square number\n",
    "    \"\"\"\n",
    "    padsize=1\n",
    "    padval=.5\n",
    "    ph=B+2*padsize\n",
    "    pw=A+2*padsize\n",
    "    batch_size=X.shape[0]\n",
    "    N=int(np.sqrt(batch_size))\n",
    "    X=X.reshape((N,N,B,A))\n",
    "    img=np.ones((N*ph,N*pw))*padval\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            startr=i*ph+padsize\n",
    "            endr=startr+B\n",
    "            startc=j*pw+padsize\n",
    "            endc=startc+A\n",
    "            img[startr:endr,startc:endc]=X[i,j,:,:]\n",
    "    return img\n",
    "\n",
    "\n",
    "    interactive = False;\n",
    "    \n",
    "    prefix=\"noattention\"\n",
    "    out_file=os.path.join(FLAGS.data_dir,\"draw_data.npy\")\n",
    "    [C,Lxs,Lzs]=np.load(out_file)\n",
    "    T,batch_size,img_size=C.shape\n",
    "    X=1.0/(1.0+np.exp(-C)) # x_recons=sigmoid(canvas)\n",
    "    B=A=int(np.sqrt(img_size))\n",
    "    if interactive:\n",
    "        f,arr=plt.subplots(1,T)\n",
    "    for t in range(T):\n",
    "        img=xrecons_grid(X[t,:,:],B,A)\n",
    "        if interactive:\n",
    "            arr[t].matshow(img,cmap=plt.cm.gray)\n",
    "            arr[t].set_xticks([])\n",
    "            arr[t].set_yticks([])\n",
    "        else:\n",
    "            plt.matshow(img,cmap=plt.cm.gray)\n",
    "            imgname='%s_%d.png' % (prefix,t) # you can merge using imagemagick, i.e. convert -delay 10 -loop 0 *.png mnist.gif\n",
    "            plt.savefig(imgname)\n",
    "            print(imgname)\n",
    "    f=plt.figure()\n",
    "    plt.plot(Lxs,label='Reconstruction Loss Lx')\n",
    "    plt.plot(Lzs,label='Latent Loss Lz')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.legend()\n",
    "    if interactive:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig('%s_loss.png' % (prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
