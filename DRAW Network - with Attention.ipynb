{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Network with attention\n",
    "\n",
    "Using code from \n",
    "\n",
    "[1]`https://github.com/ericjang/draw` \n",
    "\n",
    "[2]`https://github.com/ikostrikov/TensorFlow-VAE-GAN-DRAW`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters set\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "#Tensor flow\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn.rnn_cell import LSTMCell\n",
    "#Easy way to get the data :)\n",
    "from tensorflow.examples.tutorials import mnist\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Most of these dimensinos are used from \n",
    "A,B = 28,28 # image width,height\n",
    "img_size = B*A # the canvas size\n",
    "\n",
    "#Using the parameters from [1], as many of these dimensions aren't explicitly mentioned in the paper\n",
    "enc_size = 256 # number of hidden units / output size in LSTM\n",
    "dec_size = 256\n",
    "\n",
    "#Parameterizing the attention window:\n",
    "read_n = 5 # read glimpse grid width/height\n",
    "write_n = 5 # write glimpse grid width/height\n",
    "read_size = 2*read_n*read_n \n",
    "write_size = write_n*write_n\n",
    "z_size=10 # QSampler output size\n",
    "T=10 # MNIST generation sequence length\n",
    "\n",
    "#These are standard NN net parameters\n",
    "batch_size=100 # training minibatch size\n",
    "train_iters=5000\n",
    "learning_rate=1e-3 # learning rate for optimizer\n",
    "eps=1e-8 # epsilon for numerical stability\n",
    "\n",
    "print \"All parameters set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable roundup\n",
    "\n",
    "## Encoder RNN\n",
    "\n",
    "* x = raw data read from the mnist images\n",
    "* x_hat = error image, x - sigmoid(c_(t-1)) [equation 3 in the paper]\n",
    "\n",
    "* h = encoded data \n",
    "\n",
    "## Decoder RNN\n",
    "* z = samples drawn from the latent distribution [equation 6 in the paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Define all elementary functions needed:\n",
    "\n",
    "# Incredible abstraction in Tensorflow!\n",
    "# Define the LSTMCell\n",
    "# Documentation: https://www.tensorflow.org/versions/r0.7/tutorials/recurrent/index.html\n",
    "lstm_enc = LSTMCell(enc_size, read_size+dec_size) # encoder Op\n",
    "lstm_dec = LSTMCell(dec_size, z_size) # decoder Op\n",
    "\n",
    "DO_SHARE = None #See note below, this is a necessary hack for initialization\n",
    "\n",
    "#And define operations with those LSTMs\n",
    "def encode(state,input):\n",
    "    with tf.variable_scope(\"encoder\",reuse=DO_SHARE):\n",
    "        return lstm_enc(input,state)\n",
    "def decode(state,input):\n",
    "    with tf.variable_scope(\"decoder\",reuse=DO_SHARE):\n",
    "        return lstm_dec(input, state)\n",
    "    \n",
    "#For the Draw network with attention, we paramteri\n",
    "def attn_window(scope,h_dec,N):\n",
    "    with tf.variable_scope(scope,reuse=DO_SHARE):\n",
    "        params=linear(h_dec,5)\n",
    "    gx_,gy_,log_sigma2,log_delta,log_gamma=tf.split(1,5,params)\n",
    "    gx=(A+1)/2*(gx_+1)\n",
    "    gy=(B+1)/2*(gy_+1)\n",
    "    sigma2=tf.exp(log_sigma2)\n",
    "    delta=(max(A,B)-1)/(N-1)*tf.exp(log_delta) # batch x N\n",
    "    return filterbank(gx,gy,sigma2,delta,N)+(tf.exp(log_gamma),)\n",
    "\n",
    "def read(x,x_hat,h_dec_prev):\n",
    "    Fx,Fy,gamma=attn_window(\"read\",h_dec_prev,read_n)\n",
    "    def filter_img(img,Fx,Fy,gamma,N):\n",
    "        Fxt=tf.transpose(Fx,perm=[0,2,1])\n",
    "        img=tf.reshape(img,[-1,B,A])\n",
    "        glimpse=tf.batch_matmul(Fy,tf.batch_matmul(img,Fxt))\n",
    "        glimpse=tf.reshape(glimpse,[-1,N*N])\n",
    "        return glimpse*tf.reshape(gamma,[-1,1])\n",
    "    x=filter_img(x,Fx,Fy,gamma,read_n) # batch x (read_n*read_n)\n",
    "    x_hat=filter_img(x_hat,Fx,Fy,gamma,read_n)\n",
    "    return tf.concat(1,[x,x_hat]) # concat along feature axis\n",
    "\n",
    "def sampleQ(h_enc):\n",
    "    \"\"\"\n",
    "    Samples Zt ~ normrnd(mu,sigma) via reparameterization trick for normal dist\n",
    "    mu is (batch,z_size)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"mu\",reuse=DO_SHARE):\n",
    "        mu=linear(h_enc,z_size)\n",
    "    with tf.variable_scope(\"sigma\",reuse=DO_SHARE):\n",
    "        logsigma=linear(h_enc,z_size)\n",
    "        sigma=tf.exp(logsigma)\n",
    "    return (mu + sigma*e, mu, logsigma, sigma)\n",
    "\n",
    "# The write function sans-attention is simply the linear Wx + b\n",
    "def linear(x,output_dim):\n",
    "    \"\"\"\n",
    "    affine transformation Wx+b\n",
    "    assumes x.shape = (batch_size, num_features)\n",
    "    \"\"\"\n",
    "    w=tf.get_variable(\"w\", [x.get_shape()[1], output_dim]) \n",
    "    b=tf.get_variable(\"b\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(x,w)+b\n",
    "\n",
    "#[equation 18 from the paper]\n",
    "def write(h_dec):\n",
    "    with tf.variable_scope(\"writeW\",reuse=DO_SHARE):\n",
    "        w=linear(h_dec,write_size) # batch x (write_n*write_n)\n",
    "    N=write_n\n",
    "    w=tf.reshape(w,[batch_size,N,N])\n",
    "    Fx,Fy,gamma=attn_window(\"write\",h_dec,write_n)\n",
    "    Fyt=tf.transpose(Fy,perm=[0,2,1])\n",
    "    wr=tf.batch_matmul(Fyt,tf.batch_matmul(w,Fx))\n",
    "    wr=tf.reshape(wr,[batch_size,B*A])\n",
    "    #gamma=tf.tile(gamma,[1,B*A])\n",
    "    return wr*tf.reshape(1.0/gamma,[-1,1])\n",
    "\n",
    "\n",
    "print \"Functions defined.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def filterbank(gx, gy, sigma2,delta, N):\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(N), tf.float32), [1, -1])\n",
    "    mu_x = gx + (grid_i - N / 2 - 0.5) * delta # eq 19\n",
    "    mu_y = gy + (grid_i - N / 2 - 0.5) * delta # eq 20\n",
    "    a = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    mu_x = tf.reshape(mu_x, [-1, N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1, N, 1])\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square((a - mu_x) / (2*sigma2))) # 2*sigma2?\n",
    "    Fy = tf.exp(-tf.square((b - mu_y) / (2*sigma2))) # batch x N x B\n",
    "    # normalize, sum over A and B dims\n",
    "    Fx=Fx/tf.maximum(tf.reduce_sum(Fx,2,keep_dims=True),eps)\n",
    "    Fy=Fy/tf.maximum(tf.reduce_sum(Fy,2,keep_dims=True),eps)\n",
    "    return Fx,Fy\n",
    "\n",
    "#Initialize all variables\n",
    "cs=[0]*T # sequence of canvases\n",
    "mus,logsigmas,sigmas=[0]*T,[0]*T,[0]*T # gaussian params generated by SampleQ. We will need these for computing loss.\n",
    "x = tf.placeholder(tf.float32,shape=(batch_size,img_size)) # input (batch_size * img_size)\n",
    "e=tf.random_normal((batch_size,z_size), mean=0, stddev=1) # Qsampler noise\n",
    "\n",
    "# initial states\n",
    "h_dec_prev=tf.zeros((batch_size,dec_size))\n",
    "enc_state=lstm_enc.zero_state(batch_size, tf.float32)\n",
    "dec_state=lstm_dec.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# Build the graph/network (which is done in an unrolled state)\n",
    "for t in range(T):\n",
    "    #Initialize the previos canvas as 0s for the first run\n",
    "    c_prev = tf.zeros((batch_size,img_size)) if t==0 else cs[t-1]\n",
    "    #Create the error image\n",
    "    x_hat=x-tf.sigmoid(c_prev) # error image\n",
    "    \n",
    "    r=read(x,x_hat,h_dec_prev)\n",
    "\n",
    "    #Pass through the lstm_enc. \n",
    "    #Note that the first time encode and decode are called, the reuse flag must be false\n",
    "    #If not, we get the following error: \n",
    "    # \"\"\"Under-sharing: Variable encoder/LSTMCell/W_0 does not exist, disallowed. \n",
    "    # Did you mean to set reuse=None in VarScope?\"\"\"\n",
    "    h_enc,enc_state=encode(enc_state,tf.concat(1,[r,h_dec_prev]))\n",
    "    #Draw from the latest distribution\n",
    "    z,mus[t],logsigmas[t],sigmas[t]=sampleQ(h_enc)\n",
    "    \n",
    "    h_dec,dec_state=decode(dec_state,z)\n",
    "    cs[t]=c_prev+write(h_dec) # store results\n",
    "    h_dec_prev=h_dec\n",
    "    \n",
    "    DO_SHARE=True\n",
    "\n",
    "print \"Model defined.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss and Optimization defined\n"
     ]
    }
   ],
   "source": [
    "# Define cost functions \n",
    "# the final canvas matrix is used to parameterize a bernoulli distrbition D(X|c). Reconstruction loss\n",
    "# is negative log probability. \n",
    "def binary_crossentropy(t,o):\n",
    "    return -(t*tf.log(o+eps) + (1.0-t)*tf.log(1.0-o+eps))\n",
    "\n",
    "# reconstruction term appears to have been collapsed down to a single scalar value (rather than one per item in minibatch)\n",
    "x_recons=tf.nn.sigmoid(cs[-1])\n",
    "\n",
    "# the final canvas matrix is used to parameterize a bernoulli distrbition D(X|c). Reconstruction loss\n",
    "# is negative log probability [Equation 9]\n",
    "# However, Eric Jang's implmentation uses a mean of summed cross-entropy. The results seem reasonable so I am \n",
    "# going to stick with it for now\n",
    "Lx=tf.reduce_sum(binary_crossentropy(x,x_recons),1) # reconstruction term\n",
    "Lx=tf.reduce_mean(Lx) \n",
    "\n",
    "#The latent loss Lz is the sum LK divergence of P(Z) from Q(Z|h)\n",
    "kl_terms=[0]*T\n",
    "for t in range(T):\n",
    "    mu2=tf.square(mus[t])\n",
    "    sigma2=tf.square(sigmas[t])\n",
    "    logsigma=logsigmas[t]\n",
    "    kl_terms[t]=0.5*tf.reduce_sum(mu2+sigma2-2*logsigma,1)-T*.5 # each kl term is (1x minibatch)\n",
    "KL=tf.add_n(kl_terms) # this is 1x minibatch, corresponding to summing kl_terms from 1:T\n",
    "Lz=tf.reduce_mean(KL) # average over minibatches\n",
    "\n",
    "cost=Lx+Lz\n",
    "\n",
    "#As this can be really finnicky, I'm using Eric Jang's implentation directly here\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "grads=optimizer.compute_gradients(cost)\n",
    "for i,(g,v) in enumerate(grads):\n",
    "    if g is not None:\n",
    "        grads[i]=(tf.clip_by_norm(g,5),v) # clip gradients\n",
    "train_op=optimizer.apply_gradients(grads)\n",
    "\n",
    "print \"Loss and Optimization defined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "iter=0 : Lx: 543.944458 Lz: 1.542613\n",
      "iter=100 : Lx: 205.020157 Lz: 4.008572\n",
      "iter=200 : Lx: 199.314865 Lz: 3.124275\n",
      "iter=300 : Lx: 202.209946 Lz: 1.864911\n",
      "iter=400 : Lx: 193.502075 Lz: 1.659343\n",
      "iter=500 : Lx: 197.096466 Lz: 2.332488\n",
      "iter=600 : Lx: 194.527328 Lz: 2.655602\n",
      "iter=700 : Lx: 180.402847 Lz: 4.911880\n",
      "iter=800 : Lx: 161.686478 Lz: 4.881144\n",
      "iter=900 : Lx: 158.418243 Lz: 4.673352\n",
      "iter=1000 : Lx: 153.008209 Lz: 4.565330\n",
      "iter=1100 : Lx: 158.537537 Lz: 4.582819\n",
      "iter=1200 : Lx: 144.478500 Lz: 4.719623\n",
      "iter=1300 : Lx: 137.608810 Lz: 4.670774\n",
      "iter=1400 : Lx: 136.504745 Lz: 4.235938\n",
      "iter=1500 : Lx: 137.091232 Lz: 4.872277\n",
      "iter=1600 : Lx: 128.613373 Lz: 4.729065\n",
      "iter=1700 : Lx: 120.264236 Lz: 4.967459\n",
      "iter=1800 : Lx: 123.811806 Lz: 4.903710\n",
      "iter=1900 : Lx: 117.166840 Lz: 5.018393\n",
      "iter=2000 : Lx: 117.712608 Lz: 4.706448\n",
      "iter=2100 : Lx: 114.175720 Lz: 4.656109\n",
      "iter=2200 : Lx: 102.826096 Lz: 4.661242\n",
      "iter=2300 : Lx: 101.307236 Lz: 4.245819\n",
      "iter=2400 : Lx: 105.334808 Lz: 3.961943\n",
      "iter=2500 : Lx: 104.352402 Lz: 4.132829\n",
      "iter=2600 : Lx: 102.702034 Lz: 3.977509\n",
      "iter=2700 : Lx: 100.801720 Lz: 3.963506\n",
      "iter=2800 : Lx: 106.385880 Lz: 3.678880\n",
      "iter=2900 : Lx: 92.580780 Lz: 3.806544\n",
      "iter=3000 : Lx: 92.746201 Lz: 3.681521\n",
      "iter=3100 : Lx: 96.242889 Lz: 3.289777\n",
      "iter=3200 : Lx: 95.593903 Lz: 3.425964\n",
      "iter=3300 : Lx: 94.831207 Lz: 3.256846\n",
      "iter=3400 : Lx: 88.333084 Lz: 3.083088\n",
      "iter=3500 : Lx: 93.890213 Lz: 3.261996\n",
      "iter=3600 : Lx: 89.990273 Lz: 2.893930\n",
      "iter=3700 : Lx: 85.705254 Lz: 2.932740\n",
      "iter=3800 : Lx: 84.823975 Lz: 2.901980\n",
      "iter=3900 : Lx: 83.346367 Lz: 2.741851\n",
      "iter=4000 : Lx: 85.114822 Lz: 2.743479\n",
      "iter=4100 : Lx: 82.286484 Lz: 2.624702\n",
      "iter=4200 : Lx: 81.386757 Lz: 2.756085\n",
      "iter=4300 : Lx: 83.203400 Lz: 2.586356\n",
      "iter=4400 : Lx: 84.878883 Lz: 2.514131\n",
      "iter=4500 : Lx: 85.805740 Lz: 2.396934\n",
      "iter=4600 : Lx: 82.770485 Lz: 2.314945\n",
      "iter=4700 : Lx: 82.343948 Lz: 2.550725\n",
      "iter=4800 : Lx: 77.686218 Lz: 2.254952\n",
      "iter=4900 : Lx: 82.434372 Lz: 2.288709\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"mnist\"\n",
    "if not os.path.exists(data_directory):\n",
    "    os.makedirs(data_directory)\n",
    "train_data = mnist.input_data.read_data_sets(data_directory, one_hot=True).train # binarized (0-1) mnist data\n",
    "fetches=[]\n",
    "fetches.extend([Lx,Lz,train_op])\n",
    "Lxs=[0]*train_iters\n",
    "Lzs=[0]*train_iters\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "saver = tf.train.Saver() # saves variables learned during training\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "for i in range(train_iters):\n",
    "    xtrain,_=train_data.next_batch(batch_size) # xtrain is (batch_size x img_size)\n",
    "    feed_dict={x:xtrain}\n",
    "    results=sess.run(fetches,feed_dict)\n",
    "    Lxs[i],Lzs[i],_=results\n",
    "    if i%100==0:\n",
    "        print(\"iter=%d : Lx: %f Lz: %f\" % (i,Lxs[i],Lzs[i]))\n",
    "\n",
    "print \"Training completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualizer\n",
    "\n",
    "#Taking visualization code from Eric Jang's plot_data.py\n",
    "def xrecons_grid(X,B,A):\n",
    "    \"\"\"\n",
    "    plots canvas for single time step\n",
    "    X is x_recons, (batch_size x img_size)\n",
    "    assumes features = BxA images\n",
    "    batch is assumed to be a square number\n",
    "    \"\"\"\n",
    "    padsize=1\n",
    "    padval=.5\n",
    "    ph=B+2*padsize\n",
    "    pw=A+2*padsize\n",
    "    batch_size=X.shape[0]\n",
    "    N=int(np.sqrt(batch_size))\n",
    "    X=X.reshape((N,N,B,A))\n",
    "    img=np.ones((N*ph,N*pw))*padval\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            startr=i*ph+padsize\n",
    "            endr=startr+B\n",
    "            startc=j*pw+padsize\n",
    "            endc=startc+A\n",
    "            img[startr:endr,startc:endc]=X[i,j,:,:]\n",
    "    return img\n",
    "\n",
    "\n",
    "    interactive = False;\n",
    "    \n",
    "    prefix=\"withattention\"\n",
    "    out_file=os.path.join(FLAGS.data_dir,\"draw_data.npy\")\n",
    "    [C,Lxs,Lzs]=np.load(out_file)\n",
    "    T,batch_size,img_size=C.shape\n",
    "    X=1.0/(1.0+np.exp(-C)) # x_recons=sigmoid(canvas)\n",
    "    B=A=int(np.sqrt(img_size))\n",
    "    if interactive:\n",
    "        f,arr=plt.subplots(1,T)\n",
    "    for t in range(T):\n",
    "        img=xrecons_grid(X[t,:,:],B,A)\n",
    "        if interactive:\n",
    "            arr[t].matshow(img,cmap=plt.cm.gray)\n",
    "            arr[t].set_xticks([])\n",
    "            arr[t].set_yticks([])\n",
    "        else:\n",
    "            plt.matshow(img,cmap=plt.cm.gray)\n",
    "            imgname='%s_%d.png' % (prefix,t) # you can merge using imagemagick, i.e. convert -delay 10 -loop 0 *.png mnist.gif\n",
    "            plt.savefig(imgname)\n",
    "            print(imgname)\n",
    "    f=plt.figure()\n",
    "    plt.plot(Lxs,label='Reconstruction Loss Lx')\n",
    "    plt.plot(Lzs,label='Latent Loss Lz')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.legend()\n",
    "    if interactive:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig('%s_loss.png' % (prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
